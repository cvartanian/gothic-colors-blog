{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import csv\n",
    "import seaborn as sb\n",
    "from collections import Counter\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_text(filename):\n",
    "    \"\"\"\n",
    "    This function generates a list of tokens with punctuation\n",
    "    stopwords, and spaces removed for the whole text.\n",
    "    \"\"\"\n",
    "    text_tokens = []\n",
    "\n",
    "    file_path = \"./corpora/\" + filename\n",
    "    stop = list(set(stopwords.words('english')))\n",
    "    punc = [p for p in string.punctuation]\n",
    "    stop_punc = stop + punc + [\"''\", '``']\n",
    "\n",
    "    text = open(file_path, 'r')\n",
    "\n",
    "    for row in text:\n",
    "        tokens = pos_tag(word_tokenize(row.lower()))\n",
    "        if len(tokens) is not 0:\n",
    "            # puts everything in lowercase, removes punctuation and stopwords\n",
    "            tokens = [token for token in tokens if token[0] not in stop_punc]\n",
    "            # adds row tokens to master list\n",
    "            text_tokens.extend(tokens)\n",
    "\n",
    "    return text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenized = tokenize_text('ShelleyMary_Frankenstein_Gutenberg.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tokenized[308:321])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_color_words():\n",
    "    \"\"\"\n",
    "    Gets color words from the csv file and puts them into a dict where key = word\n",
    "    and value = hex value.\n",
    "    \"\"\"\n",
    "    color_word_dict = {}\n",
    "    modern_color_words = []\n",
    "    color_data = csv.reader(open('./color_names.csv'), delimiter=\",\", quotechar='\"')\n",
    "    next(color_data, None)\n",
    "\n",
    "    for row in color_data:\n",
    "        name = row[0].lower()\n",
    "        year = int(row[1])\n",
    "        if ' ' not in name:\n",
    "            if year < 1914:\n",
    "                family = row[2].lower()\n",
    "                hex_value = row[3].lower()\n",
    "                color_word_dict[name] = (hex_value, family)\n",
    "            else:\n",
    "                modern_color_words.append((year, name))\n",
    "                   \n",
    "    return color_word_dict, modern_color_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_dict, modern_color_words = get_color_words()\n",
    "print(\"There are %d color words in our dictionary that were in use before 1914, per the OED.\" % len(color_dict))\n",
    "print()\n",
    "sample_colors = list(color_dict.keys())[400:410]\n",
    "print(\"Here is a sample - first value is the HTML color, the second is the color family.\")\n",
    "for s in sample_colors:\n",
    "    print(s, \":\", color_dict[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Here are the post-1914 words and the year of first usage according to the Oxford English Dictionary.\")\n",
    "print(\"The 20th century ushered in food-related color words including avocado, citron, cocoa, mustard, pimento & toffee.\")\n",
    "print()\n",
    "print(sorted(modern_color_words, key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_color_words(c_dict, text):\n",
    "    tags = ['NN', 'JJ']\n",
    "    color_names = list(c_dict.keys())\n",
    "    color_words = [w for w in text if w[0] in color_names and w[1] in tags]\n",
    "    \n",
    "    return color_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_in_text = get_color_words(color_dict, tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(color_in_text[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nouns = Counter([n[0] for n in color_in_text if n[1] == 'NN'])\n",
    "adjectives = Counter([a[0] for a in color_in_text if a[1] == 'JJ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"*** Nouns ***\")\n",
    "print(nouns)\n",
    "print(\"*** Adjectives ***\")\n",
    "print(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_to_plot(color_dict, c_i_t):\n",
    "    color_summary = Counter()\n",
    "    for c in c_i_t:\n",
    "        color_summary[color_dict[c[0]][0]] += 1\n",
    "    print(color_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_to_plot(color_dict, color_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:potter]",
   "language": "python",
   "name": "conda-env-potter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
