{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"gothic.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If someone says “gothic” to you, do you think of lush rolling countryside or a sunny day?\n",
    "\n",
    "Chances are you don’t.  Most people - myself included - associate that word with things that are dark, mysterious and even frightening.  Maybe you picture ornate stone architecture of a castle with gargoyles. Or perhaps foreboding skies rolling over said castle.  Or very morose, pale people wearing black capes and veils.  Or vampires with all of the above.\n",
    "\n",
    "About a year ago, [Caroline Winter](https://carolinewinter.com/), a PhD student at the University of Victoria, emailed me with a question.  She had assembled a [corpus of 134 works of European Gothic literature](https://github.com/eleanorstrib/gothic/tree/master/corpora) that had been written or translated into English, ranging from the 18th century to the early 20th.  Could I write her a short script to count and analyze color words for a broad corpus she’d assembled as a survey of Gothic literature she was studying?  Because her hunch was that gothic literature was greener and less bleak and grim than most people thought.\n",
    "\n",
    "This post tells the story of how a quick Python project for a Sunday afternoon morphed into a talk at PyCon.  Through some straightforward counting and matching techniques, we were able to find some interesting patterns that challenged my gloomy picture of “gothic”.  \n",
    "\n",
    "This Jupyter Notebook is a companion to the post on the [Kite.com blog](https://kite.com/blog) published in October 2018.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first let's import the libraries and functions we need\n",
    "import csv\n",
    "from itertools import tee\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for this example, I've selected one text from the \"corpora\" folder; the path will be added when we run the function\n",
    "title_file = 'Leroux_ThePhantomOfTheOpera_Gutenberg.txt'\n",
    "title = \"The Phantom of the Opera\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond black, white and red\n",
    "\n",
    "The first step in the project was to define which color words we were looking for. The challenge here was that both the vocabulary used to describe color and the actual coloring of objects themselves were different in the gothic era than we think of them in the late 2010s.\n",
    "\n",
    "Rather than guess about historical color words, we turned to the [Oxford English Dictionary’s Historical Thesaurus](http://www.oed.com/public/htoed/loginpage) (hereafter the <i>Historical Thesaurus</i>).  It lists color words used in English and primarily in Europe, the year of each one’s first recorded use, and its color family.  \n",
    "\n",
    "After adding some html color names based on color grouping to our csv file of the [original data set](https://github.com/eleanorstrib/gothic-colors-blog/blob/master/color_names.csv), I read a csv file with the Historical Thesaurus data into a short function and eliminated everything that came into usage after 1914, since it’s not clear from the data when words fell out of usage.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def id_color_words():\n",
    "    \"\"\"\n",
    "    Gets color words from the csv file and puts them into a dict where key = word\n",
    "    and value = (hex value, color family); removes pre-1914 color words.\n",
    "    \"\"\"\n",
    "    color_word_dict = {}\n",
    "    modern_color_words = []\n",
    "    color_data = csv.DictReader(open('./color_names.csv'), delimiter=\",\", quotechar='\"')\n",
    "\n",
    "    for row in color_data:\n",
    "        name = row['Colour Name'].lower()\n",
    "        year = int(row['First Usage'])\n",
    "        if ' ' not in name:\n",
    "            if year < 1914:\n",
    "                family = row['Colour Family'].lower()\n",
    "                hex_value = row['hex'].lower()\n",
    "                color_word_dict[name] = (hex_value, family)\n",
    "            else:\n",
    "                modern_color_words.append((year, name))\n",
    "                   \n",
    "    return color_word_dict, modern_color_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave us a dictionary of 980 pre-WWI color words ranging from the familiar, like blue (first usage in 1300), crimson (1416), or jet (1607), to the uncommon, like corbeau (1810, dark green), damask (1598, pink) or ochroid (1897, pale yellow).  There were also some instances where the way words were categorized reflected a historical state of familiar things. For example, ‘glass’ is categorized as a greyish green, not pale blue or clear as we may think of it today.\n",
    "\n",
    "Now we knew what we were looking for, but generating an accurate analysis was about more than simply counting these color words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_dict, modern_color_words = id_color_words()\n",
    "\n",
    "print(\"There are %d color words in our dictionary that were in use before 1914, per the OED.\" % len(color_dict))\n",
    "print()\n",
    "sample_colors = list(color_dict.keys())[230:240]\n",
    "print(\"Here is a sample - first value in the tuple is the HTML color, the second is the color family.\")\n",
    "for s in sample_colors:\n",
    "    print(s, \":\", color_dict[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what we're discarding from the data set is also interesting\n",
    "print(\"Here are the post-1914 words and the year of first usage according to the Oxford English Dictionary.\")\n",
    "print(\"The 20th century ushered in food-related color words including avocado, citron, cocoa, mustard, pimento & toffee.\")\n",
    "print()\n",
    "print(json.dumps(dict(sorted(modern_color_words, key=lambda x: x[0])), indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‘rose’ != ‘rose’ != ‘rose’\n",
    "<div align=\"center\" style=\"margin: 0 auto;\">\n",
    "    <div style=\"width: 50%;float: left;\"><img src=\"roseisarose.gif\"></div>\n",
    "    <div><p>\n",
    "    English is a tricky language, with many words that sound the same mean different things and many words that look the same mean different things in context. ‘Rose’ is a great example: it can be a noun, adjective or a verb, as demonstrated in the gif below.\n",
    "\n",
    "<p>So which words should we count?  Should every word on the list be included?\n",
    "\n",
    "<p>To make this decision, we needed to write more code to parse our corpus and look at the results. \n",
    "\n",
    "<p>The function below, `process_text` reads in the text file for a single work, removes the “gristle” - stop words, punctuation, and puts remaining words all in lowercase - then tags them for part of speech (noun, verb, adjective, etc.) using the Natural Language Toolkit (NLTK) ‘pos_tag’ function.</p>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_text(filename):\n",
    "    \"\"\"\n",
    "    This function generates a list of tokens with punctuation stopwords, and spaces removed for the whole text.\n",
    "    It also applies NLTK's part of speech tagging function to determine if words are nouns, adjectives, verbs, etc.\n",
    "    \"\"\"\n",
    "    text_tokens = []\n",
    "    \n",
    "    # create a list of the words and punctuation we want to remove before analyzing\n",
    "    stop_punc = set(stopwords.words('english') + [*string.punctuation] + [\"''\", '``'])\n",
    "    \n",
    "    with open(filename) as text:\n",
    "        for row in text:\n",
    "            # puts everything in lowercase, postion tags\n",
    "            for token in pos_tag(word_tokenize(row.lower())):\n",
    "                #removes tokens if contains punctuation or stopwords\n",
    "                if token and token[0] not in stop_punc:\n",
    "                    text_tokens.append(token)\n",
    "\n",
    "    return text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's run the function and look at a sample of the data we've generated\n",
    "processed = process_text(title_file)\n",
    "print(processed[300:320])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "\n",
    "def is_color_word(word, color_dict):\n",
    "    color, tag = word\n",
    "    tags = {'JJ', 'NN'} # JJ = adjectives, NN = nouns\n",
    "    return tag in tags and color in color_dict\n",
    "\n",
    "\n",
    "def find_color_words(t, color_dict):\n",
    "    \"\"\"\n",
    "    This function identifies adjectives and nouns in the text that match contemporary color words in the color_dict,\n",
    "    then checks to see if the word before or after it is also a color word to help the analyst determine if they want\n",
    "    to count instances where two color words are found together - e.g. \"red rose\", or \"white marble\"\n",
    "    \"\"\"\n",
    "    color_words = []\n",
    "    concurrent_color_words = []\n",
    "    \n",
    "    for p, n in pairwise(t):\n",
    "        if is_color_word(p, color_dict) and is_color_word(n, color_dict):\n",
    "            concurrent_color_words.append((p, n))\n",
    "    for o in t:\n",
    "        if is_color_word(o, color_dict):\n",
    "            color_words.append(o)\n",
    "    return color_words, concurrent_color_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_in_text, concurrent_color_words = find_color_words(processed, color_dict)\n",
    "\n",
    "print(\"Here's a sample of what our list of color words looks like:\")\n",
    "print(color_in_text[:20])\n",
    "print()\n",
    "if len(concurrent_color_words) > 1:\n",
    "    print(\"Here is a sample of the concurrent color words, instances where we had a color noun with a color adjective:\")\n",
    "    print(concurrent_color_words[:10])\n",
    "else:\n",
    "    print(\"No concurrent color words (e.g. 'red rose' or 'yellow orange') were found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function outputs the whole text that looks like this - as you can see `pos_tag` doesn’t look like it gets the part of speech correct every time, but it’s pretty close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Here's a sample of what our list of color words looks like:\")\n",
    "print(color_in_text[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s what we get from this function.\n",
    "\n",
    "First, a list of all of the identified color words in the text and their tag, like this:\n",
    "\n",
    "`[('yellow', 'JJ'), ('black', 'JJ'), ('mourning', 'NN'), ('rose-red', 'JJ'), ('lily-white', 'JJ'), ('black', 'JJ'), ('black', 'JJ'), ('black', 'JJ'), ('white', 'JJ'), ('yellow', 'NN'), ('plum', 'NN'), ('glass', 'NN'), ('red', 'JJ'), ('coral', 'JJ'), ('pink', 'NN'), ('iron', 'NN'), ('glass', 'NN'), ('pink', 'JJ'), ('candid', 'JJ'), ('blue', 'JJ')]`\n",
    "\n",
    "Second, we get a list of tuples containing the color words that were adjectives or nouns followed by another adjective or noun closely in the original text.  From The Phantom of the Opera, we get examples like:\n",
    "`(('glass', 'NN'), ('champagne', 'NN'))\n",
    "(('pink', 'NN'), ('white', 'JJ'))\n",
    "(('gold', 'NN'), ('purple', 'NN'))\n",
    "(('water', 'NN'), ('bluey', 'NN'))`\n",
    "In most cases we didn’t think one of these took anything away from or obscured the other; in fact their close association painted a clearer picture of color and in some cases texture.  So we left both words in.\n",
    "\n",
    "From this you can get some summary stats, like what percentage of the uncommon words in the text were color words (Phantom is 0.9%), and what proportion are nouns versus adjectives (Phantom is 52-47).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#some descriptive statistics!\n",
    "nouns = Counter([n[0] for n in color_in_text if n[1] == 'NN'])\n",
    "total_nouns = sum(nouns.values())\n",
    "adjectives = Counter([a[0] for a in color_in_text if a[1] == 'JJ'])\n",
    "total_adjectives = sum(adjectives.values())\n",
    "total_color_words = len(color_in_text)\n",
    "pct_color_words = round((total_color_words/len(processed))*100, 2)\n",
    "\n",
    "print(\"There are %d nouns in our color word list:\" % total_nouns)\n",
    "print(nouns)\n",
    "print()\n",
    "print(\"And %d adjectives in our color word list:\" % total_adjectives)\n",
    "print(adjectives)\n",
    "print()\n",
    "print(\"%s is %s percent color words.\"% (title, pct_color_words))\n",
    "print(\"~%d percent of the color words are nouns.\" % round((total_nouns/total_color_words)*100, 1))\n",
    "print(\"~%d percent of the color words are adjectives.\" % round((total_adjectives/total_color_words)*100, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we needed to isolate the color words from the text and do some analysis of the context to make sure there weren’t any glaring issues in the data we were generating.  Here Caroline’s literature background was extremely helpful in identifying what looked off, and I went off to pull out the context of the suspicious words so she could make a final call.\n",
    "\n",
    "Some examples of words we eliminated based on context were:\n",
    "Isabella, a yellowish color that was also the name of a couple of characters in our corpus;\n",
    "Imperial, a purple color that, in the texts actually meant the political structure, not the color; and\n",
    "Angry, sometimes used to describe a red-pink flushed color, but was used more an an emotion word than a color word.\n",
    "\n",
    "At this stage, I also experimented with stemming and lemmatization of the color words in our master list and in the texts themselves to see if that changed how many color words we were finding, rather than looking for exact matches.  What this means, for example, is transforming the word “whitish” from the OEDHT to its root, or stem (“white”) and doing the same to the words in the text we were analyzing. However, because the OEDHT is so comprehensive and already included many forms of each word, the results didn’t change much so we left out that step.\n",
    "\n",
    "Looking at the preliminary data, we also found that we got some combinations of color words, like “rose” followed by “red” or “milky” followed by “white”.  While OEDHT covers common combinations of these when they’re joined with a “-” (e.g. “rose-red”) we decided to isolate those examples in the output of the `find_color_words` to help us determine if we wanted to exclude those samples from the final analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis & Visualization - the (really) fun part\n",
    "With adjustments made to the color word list, we were ready to run the texts through our `find_color_words` function again to see the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_to_plot(color_dict, c_i_t):\n",
    "    color_summary = defaultdict(int)\n",
    "    for c in c_i_t:\n",
    "        color_summary[color_dict[c[0]][0]] += 1\n",
    "    color_sum_a = dict(OrderedDict(sorted(color_summary.items(), key=lambda t: t[1])))\n",
    "    color_sum_d = dict(OrderedDict(sorted(color_summary.items(), key=lambda t: t[1], reverse=True)))\n",
    "    return color_sum_a, color_sum_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html_color_counts_asc, html_color_counts_dsc  = group_to_plot(color_dict, color_in_text)\n",
    "print (json.dumps(html_color_counts_dsc, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use matplotlib to add a bar chart of the top 10 colors in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = list(html_color_counts_asc.keys())[-9:]\n",
    "counts = list(html_color_counts_asc.values())[-9:]\n",
    "y_pos = np.arange(len(counts))\n",
    "\n",
    "plt.barh(y_pos, counts, align='center', color=colors)\n",
    "plt.yticks(y_pos, colors)\n",
    "plt.xlabel('# times evoked')\n",
    "plt.title('Top 10 HTML colors in ' + title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many of interesting options for visualizing this data. The original talk included a [website](https://afternoon-taiga-69837.herokuapp.com/), built with the Django framework and ChartJS and lots of CSS where - using a slightly different methodology - we visualized each book as a series of color blocks in their order of appearance, and each author's works as a radial chart.\n",
    "\n",
    "<img src='phantom.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond this post\n",
    "If you take a few minutes to explore the website, even with the limitations of HTML color applied to a broad palette, you’ll see that a lot of the books are not as dark and gloomy as their “gothic” label might lead you to believe.  This makes sense: the supernatural is a strong theme in Gothic, but so is contrasting it with the beauty of natural world that was considered both a haven and a dwindling reality as the industrial revolution began.\n",
    "\n",
    "There is so many ways that computing could be used for humanities scholarship to complement the strong traditions already there.  If you’d like to learn more about this project after reviewing , please [watch the original talk](https://www.youtube.com/watch?v=3dDtACSYVx0) and [visit the website](https://afternoon-taiga-69837.herokuapp.com/), check out the [repo and the corpus](https://github.com/eleanorstrib/gothic).  If you prefer to work with more recent literature, check out my 2018 project where I [explain and quantify gender bias in the Harry Potter series using Python](https://medium.com/agatha-codes/a-bossy-sort-of-voice-3c3a18de3093). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
